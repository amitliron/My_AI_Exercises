{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "146f7472",
   "metadata": {},
   "source": [
    "# Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6d8b6b",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/mariafrenti/age-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b39379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "460a88ea",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5346787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Auto reload:\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9501d5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "169b3bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amitli/OrYair/orYairVenv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from matplotlib                          import pyplot\n",
    "from matplotlib.image                    import imread\n",
    "from torchvision.datasets                import ImageFolder\n",
    "from torch.optim.lr_scheduler            import OneCycleLR\n",
    "from sklearn.metrics                     import r2_score\n",
    "\n",
    "\n",
    "import numpy                  as np\n",
    "import matplotlib.pyplot      as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn               as nn\n",
    "import torch.nn.functional    as F\n",
    "import torch.optim            as optim\n",
    "import torchinfo\n",
    "\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import matplotlib\n",
    "import torchvision\n",
    "import torchinfo\n",
    "import gc \n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc8e5c9",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be9c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FOLDER = \"/home/amitli/Datasets/Age prediction/20-50/train\"\n",
    "TEST_FOLDER  = \"/home/amitli/Datasets/Age prediction/20-50/test\"\n",
    "\n",
    "\n",
    " #-- ImageNet statistics:\n",
    "vMean = np.array([0.48501961, 0.45795686, 0.40760392])\n",
    "vStd  = np.array([0.22899216, 0.224     , 0.225     ])\n",
    "\n",
    "oTransforms = transforms.Compose([\n",
    "    #transforms.Resize    (224),\n",
    "    #transforms.CenterCrop(224),\n",
    "    transforms.ToTensor  (),\n",
    "    transforms.Normalize (mean=vMean, std=vStd),\n",
    "])\n",
    "\n",
    "\n",
    "batchSize            = 32\n",
    "oDataSet             = ImageFolder(root=TRAIN_FOLDER, transform=oTransforms)\n",
    "oTrainSet, oTestSet  = torch.utils.data.random_split(oDataSet, np.round([0.9 * len(oDataSet), 0.1 * len(oDataSet)]).astype(int))\n",
    "\n",
    "oTrainSet.transform  = oTransforms\n",
    "oTestSet .transform  = oTransforms\n",
    "\n",
    "oTrainDL  = torch.utils.data.DataLoader(oTrainSet,   batch_size=batchSize, num_workers=2, persistent_workers=True)\n",
    "oTestDL   = torch.utils.data.DataLoader(oTestSet,    batch_size=batchSize, num_workers=2, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b4133e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e43d444",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc23de04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y) in enumerate(oTrainDL):\n",
    "    print (x[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48ba985",
   "metadata": {},
   "source": [
    "# Prepare GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7543e38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f61ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "668f0d2f",
   "metadata": {},
   "source": [
    "# Model (Resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304038c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c268441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPretrainedModel():\n",
    "    oModel = torchvision.models.resnet50(pretrained=True)\n",
    "    #-- freeze weights:\n",
    "    for mParam in oModel.parameters():\n",
    "        if False == isinstance(mParam, nn.BatchNorm2d):\n",
    "            mParam.requires_grad = False\n",
    "        \n",
    "    #-- Replace classifier head:\n",
    "    dIn       = oModel.fc.in_features\n",
    "    oModel.fc = nn.Sequential(\n",
    "        nn.Linear(dIn, 512), nn.ReLU(),\n",
    "        nn.Linear(512, 256), nn.ReLU(),\n",
    "        nn.Linear(256, 128), nn.ReLU(),\n",
    "        nn.Linear(128, 31)\n",
    "    )\n",
    "    \n",
    "    return oModel\n",
    "\n",
    "torchinfo.summary(GetPretrainedModel(), (32, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614cb27c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df5b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(mScore, vY):\n",
    "    vHatY = mScore.detach().argmax(dim=1)\n",
    "    return (vHatY == vY).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96335a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70cbb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Epoch(oModel, oDataDL, Loss, Metric, oOptim=None, oScheduler=None, bTrain=True):\n",
    "\n",
    "    epochLoss   = 0\n",
    "    epochMetric = 0\n",
    "    count       = 0\n",
    "    nIter       = len(oDataDL)\n",
    "    vLR         = np.full(nIter, np.nan)\n",
    "    DEVICE      = next(oModel.parameters()).device #-- CPU\\GPU\n",
    "\n",
    "\n",
    "    oModel.train(bTrain) #-- train or test\n",
    "\n",
    "    #-- Iterate over the mini-batches:\n",
    "    for ii, (mX, vY) in enumerate(oDataDL):\n",
    "        #-- Move to device (CPU\\GPU):\n",
    "        mX = mX.to(DEVICE)\n",
    "        vY = vY.to(DEVICE)\n",
    "                \n",
    "        #-- Forward:\n",
    "        if bTrain == True:\n",
    "            #-- Store computational graph:\n",
    "            mZ   = oModel(mX)                        \n",
    "            loss = Loss(mZ, vY)           \n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                #-- Do not store computational graph:\n",
    "                mZ   = oModel(mX)                \n",
    "                loss = Loss(mZ, vY)\n",
    "\n",
    "        #-- Backward:\n",
    "        if bTrain == True:\n",
    "            oOptim.zero_grad() #-- set gradients to zeros\n",
    "            loss.backward()    #-- backward\n",
    "            oOptim.step()      #-- update parameters\n",
    "            if oScheduler is not None:\n",
    "                vLR[ii] = oScheduler.get_last_lr()[0]\n",
    "                oScheduler.step() #-- update learning rate\n",
    "\n",
    "        Nb           = vY.shape[0]\n",
    "        count       += Nb\n",
    "        epochLoss   += Nb * loss.item()\n",
    "        epochMetric += Nb * Metric(mZ, vY)\n",
    "        print(f'\\r{\"Train\" if bTrain else \"Val\"} - Iteration: {ii:3d} ({nIter}): loss = {loss:2.6f}', end='')\n",
    "\n",
    "    print('', end='\\r')\n",
    "    epochLoss   /= count\n",
    "    epochMetric /= count\n",
    "\n",
    "    return epochLoss, epochMetric, vLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd76eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01086f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# AUTO ENCODER\n",
    "#\n",
    "\n",
    "def Epoch(oModel, oDataDL, Loss, Metric, oOptim=None, oScheduler=None, bTrain=True):\n",
    "\n",
    "    epochLoss   = 0\n",
    "    epochMetric = 0\n",
    "    count       = 0\n",
    "    nIter       = len(oDataDL)\n",
    "    vLR         = np.full(nIter, np.nan)\n",
    "    DEVICE      = next(oModel.parameters()).device #-- CPU\\GPU\n",
    "\n",
    "    oModel.train(bTrain) #-- train or test\n",
    "\n",
    "    #-- Iterate over the mini-batches:\n",
    "    for ii, (mX, _) in enumerate(oDataDL):\n",
    "        #-- Move to device (CPU\\GPU):\n",
    "        mX = mX.to(DEVICE)\n",
    "\n",
    "        if bTrain == True:\n",
    "            #-- Forward:\n",
    "            mHatX = oModel(mX)\n",
    "            loss  = Loss  (mHatX, mX)\n",
    "                    \n",
    "            #-- Backward:\n",
    "            vLR[ii] = oScheduler.get_last_lr()[0]\n",
    "            oOptim    .zero_grad() #-- set gradients to zeros\n",
    "            loss      .backward () #-- backward\n",
    "            oOptim    .step     () #-- update parameters\n",
    "            oScheduler.step     () #-- update learning rate\n",
    "\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                #-- Forward:\n",
    "                mHatX = oModel(mX)\n",
    "                loss  = Loss  (mHatX, mX)\n",
    "\n",
    "        Nb           = mX.shape[0]\n",
    "        count       += Nb\n",
    "        epochLoss   += Nb * loss.item()\n",
    "        epochMetric += Nb * Metric(mHatX, mX)\n",
    "        print(f'\\r{\"Train\" if bTrain else \"Val\"} - Iteration: {ii:3d} ({nIter}): loss = {loss:2.6f}', end='')\n",
    "\n",
    "    print('', end='\\r')\n",
    "    epochLoss   /= count\n",
    "    epochMetric /= count\n",
    "\n",
    "    return epochLoss, epochMetric, vLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6c66ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b77b6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(oModel, oTrainData, oValData, Loss, Metric, nEpochs, oOptim, oScheduler=None, Epoch=Epoch, sModelName='BestParams'):\n",
    "\n",
    "    vTrainLoss   = np.full(nEpochs, np.nan)\n",
    "    vTrainMetric = np.full(nEpochs, np.nan)\n",
    "    vValLoss     = np.full(nEpochs, np.nan)\n",
    "    vValMetric   = np.full(nEpochs, np.nan)\n",
    "    vLR          = np.full(0,       np.nan)\n",
    "    bestMetric   = -float('inf')\n",
    "\n",
    "    for epoch in range(nEpochs):\n",
    "        startTime                    = time.time()\n",
    "        trainLoss, trainMetric, vLRi = Epoch(oModel, oTrainData, Loss, Metric, oOptim, oScheduler, bTrain=True ) #-- train\n",
    "        valLoss,   valMetric,   _    = Epoch(oModel, oValData,   Loss, Metric,                     bTrain=False) #-- validate\n",
    "        epochTime                    = time.time() - startTime\n",
    "\n",
    "        #-- Display:\n",
    "        if epoch % 10 == 0:\n",
    "            print('-' * 120)\n",
    "        print('Epoch '            f'{epoch       :03d}:',   end='')\n",
    "        print(' | Train loss: '   f'{trainLoss   :6.3f}',   end='')\n",
    "        print(' | Val loss: '     f'{valLoss     :6.3f}',   end='')\n",
    "        print(' | Train Metric: ' f'{trainMetric :6.3f}',   end='')\n",
    "        print(' | Val Metric: '   f'{valMetric   :6.3f}',   end='')\n",
    "        print(' | epoch time: '   f'{epochTime   :6.3f} |', end='')\n",
    "\n",
    "        vTrainLoss  [epoch] = trainLoss\n",
    "        vTrainMetric[epoch] = trainMetric\n",
    "        vValLoss    [epoch] = valLoss\n",
    "        vValMetric  [epoch] = valMetric\n",
    "        vLR                 = np.concatenate([vLR, vLRi])\n",
    "\n",
    "        #-- Save best model (early stopping):\n",
    "        if valMetric > bestMetric:\n",
    "            bestMetric = valMetric\n",
    "            try   : torch.save(oModel.state_dict(), sModelName + '.pt')\n",
    "            except: pass\n",
    "            print(' <-- Checkpoint!')\n",
    "        else:\n",
    "            print('')\n",
    "\n",
    "    #-- Load best model (early stopping):\n",
    "    oModel.load_state_dict(torch.load(sModelName + '.pt'))\n",
    "\n",
    "    return vTrainLoss, vTrainMetric, vValLoss, vValMetric, vLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07871a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07cc4732",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d8b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "nEpochs    = 20\n",
    "nIter      = nEpochs * len(oTrainDL)\n",
    "Loss       = nn.CrossEntropyLoss()\n",
    "oModel     = GetPretrainedModel     ().to(DEVICE)\n",
    "oOptim     = optim.AdamW            (oModel.parameters(), lr=1e-4, betas=(0.9, 0.99), weight_decay=2e-4)\n",
    "oScheduler = OneCycleLR             (oOptim, max_lr=2e-2, total_steps=nIter)\n",
    "lHistory   = TrainClassficationModel(oModel, oTrainDL, oTestDL, Loss, nEpochs, oOptim, oScheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1203a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "937c942b",
   "metadata": {},
   "source": [
    "# Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53304777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00a36765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               --                        --\n",
       "├─Identity: 1-1                          [32, 3, 128, 128]         --\n",
       "├─Conv2d: 1-2                            [32, 8, 126, 126]         216\n",
       "├─BatchNorm2d: 1-3                       [32, 8, 126, 126]         16\n",
       "├─ReLU: 1-4                              [32, 8, 126, 126]         --\n",
       "├─Conv2d: 1-5                            [32, 16, 124, 124]        1,152\n",
       "├─BatchNorm2d: 1-6                       [32, 16, 124, 124]        32\n",
       "├─ReLU: 1-7                              [32, 16, 124, 124]        --\n",
       "├─MaxPool2d: 1-8                         [32, 16, 62, 62]          --\n",
       "├─Conv2d: 1-9                            [32, 32, 60, 60]          4,608\n",
       "├─BatchNorm2d: 1-10                      [32, 32, 60, 60]          64\n",
       "├─ReLU: 1-11                             [32, 32, 60, 60]          --\n",
       "├─Conv2d: 1-12                           [32, 32, 58, 58]          9,216\n",
       "├─BatchNorm2d: 1-13                      [32, 32, 58, 58]          64\n",
       "├─ReLU: 1-14                             [32, 32, 58, 58]          --\n",
       "├─MaxPool2d: 1-15                        [32, 32, 29, 29]          --\n",
       "├─Conv2d: 1-16                           [32, 32, 27, 27]          9,216\n",
       "├─BatchNorm2d: 1-17                      [32, 32, 27, 27]          64\n",
       "├─ReLU: 1-18                             [32, 32, 27, 27]          --\n",
       "├─Conv2d: 1-19                           [32, 64, 25, 25]          18,432\n",
       "├─BatchNorm2d: 1-20                      [32, 64, 25, 25]          128\n",
       "├─ReLU: 1-21                             [32, 64, 25, 25]          --\n",
       "├─MaxPool2d: 1-22                        [32, 64, 12, 12]          --\n",
       "├─Conv2d: 1-23                           [32, 64, 10, 10]          36,864\n",
       "├─BatchNorm2d: 1-24                      [32, 64, 10, 10]          128\n",
       "├─ReLU: 1-25                             [32, 64, 10, 10]          --\n",
       "├─Conv2d: 1-26                           [32, 64, 8, 8]            36,864\n",
       "├─BatchNorm2d: 1-27                      [32, 64, 8, 8]            128\n",
       "├─ReLU: 1-28                             [32, 64, 8, 8]            --\n",
       "├─MaxPool2d: 1-29                        [32, 64, 4, 4]            --\n",
       "├─Conv2d: 1-30                           [32, 64, 2, 2]            36,864\n",
       "├─BatchNorm2d: 1-31                      [32, 64, 2, 2]            128\n",
       "├─ReLU: 1-32                             [32, 64, 2, 2]            --\n",
       "├─MaxPool2d: 1-33                        [32, 64, 1, 1]            --\n",
       "├─Conv2d: 1-34                           [32, 2, 1, 1]             130\n",
       "├─Flatten: 1-35                          [32, 2]                   --\n",
       "==========================================================================================\n",
       "Total params: 154,314\n",
       "Trainable params: 154,314\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.98\n",
       "==========================================================================================\n",
       "Input size (MB): 6.29\n",
       "Forward/backward pass size (MB): 343.02\n",
       "Params size (MB): 0.62\n",
       "Estimated Total Size (MB): 349.92\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GetEncoder():\n",
    "    oEncoder = nn.Sequential(\n",
    "        nn.Identity(),\n",
    "        nn.Conv2d(3,  8,  kernel_size=3, bias=False), nn.BatchNorm2d(8 ), nn.ReLU(), \n",
    "        nn.Conv2d(8,  16, kernel_size=3, bias=False), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        nn.Conv2d(16, 32, kernel_size=3, bias=False), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "        nn.Conv2d(32, 32, kernel_size=3, bias=False), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        nn.Conv2d(32, 32, kernel_size=3, bias=False), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "        nn.Conv2d(32, 64, kernel_size=3, bias=False), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        nn.Conv2d(64, 64, kernel_size=3, bias=False), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "        nn.Conv2d(64, 64, kernel_size=3, bias=False), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        nn.Conv2d(64, 64, kernel_size=3, bias=False), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        nn.Conv2d(64, 2,  kernel_size=1), \n",
    "        nn.Flatten()\n",
    "    )\n",
    "    \n",
    "    return oEncoder\n",
    "#=============================================================#\n",
    "#=============================================================#\n",
    "torchinfo.summary(GetEncoder(), (32, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a1b5611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               --                        --\n",
       "├─Identity: 1-1                          [32, 2]                   --\n",
       "├─Unflatten: 1-2                         [32, 2, 1, 1]             --\n",
       "├─Upsample: 1-3                          [32, 2, 3, 3]             --\n",
       "├─Conv2d: 1-4                            [32, 8, 4, 4]             64\n",
       "├─BatchNorm2d: 1-5                       [32, 8, 4, 4]             16\n",
       "├─ReLU: 1-6                              [32, 8, 4, 4]             --\n",
       "├─Upsample: 1-7                          [32, 8, 8, 8]             --\n",
       "├─Conv2d: 1-8                            [32, 16, 8, 8]            1,152\n",
       "├─BatchNorm2d: 1-9                       [32, 16, 8, 8]            32\n",
       "├─ReLU: 1-10                             [32, 16, 8, 8]            --\n",
       "├─Upsample: 1-11                         [32, 16, 16, 16]          --\n",
       "├─Conv2d: 1-12                           [32, 32, 16, 16]          4,608\n",
       "├─BatchNorm2d: 1-13                      [32, 32, 16, 16]          64\n",
       "├─ReLU: 1-14                             [32, 32, 16, 16]          --\n",
       "├─Upsample: 1-15                         [32, 32, 32, 32]          --\n",
       "├─Conv2d: 1-16                           [32, 40, 32, 32]          11,520\n",
       "├─BatchNorm2d: 1-17                      [32, 40, 32, 32]          80\n",
       "├─ReLU: 1-18                             [32, 40, 32, 32]          --\n",
       "├─Upsample: 1-19                         [32, 40, 64, 64]          --\n",
       "├─Conv2d: 1-20                           [32, 40, 64, 64]          14,400\n",
       "├─BatchNorm2d: 1-21                      [32, 40, 64, 64]          80\n",
       "├─ReLU: 1-22                             [32, 40, 64, 64]          --\n",
       "├─Upsample: 1-23                         [32, 40, 128, 128]        --\n",
       "├─Conv2d: 1-24                           [32, 40, 128, 128]        14,400\n",
       "├─BatchNorm2d: 1-25                      [32, 40, 128, 128]        80\n",
       "├─ReLU: 1-26                             [32, 40, 128, 128]        --\n",
       "├─Conv2d: 1-27                           [32, 3, 128, 128]         1,080\n",
       "├─Sigmoid: 1-28                          [32, 3, 128, 128]         --\n",
       "==========================================================================================\n",
       "Total params: 47,576\n",
       "Trainable params: 47,576\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 10.42\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 457.77\n",
       "Params size (MB): 0.19\n",
       "Estimated Total Size (MB): 457.96\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GetDecoder():\n",
    "    oDecoder = nn.Sequential(\n",
    "        nn.Identity(),\n",
    "        nn.Unflatten(1, (2, 1, 1)),\n",
    "        nn.Upsample(scale_factor=3), nn.Conv2d(2,  8,  kernel_size=2, padding=1, bias=False), nn.BatchNorm2d(8 ), nn.ReLU(), \n",
    "        nn.Upsample(scale_factor=2), nn.Conv2d(8,  16, kernel_size=3, padding=1, bias=False), nn.BatchNorm2d(16), nn.ReLU(), \n",
    "        nn.Upsample(scale_factor=2), nn.Conv2d(16, 32, kernel_size=3, padding=1, bias=False), nn.BatchNorm2d(32), nn.ReLU(), \n",
    "        nn.Upsample(scale_factor=2), nn.Conv2d(32, 40, kernel_size=3, padding=1, bias=False), nn.BatchNorm2d(40), nn.ReLU(), \n",
    "        nn.Upsample(scale_factor=2), nn.Conv2d(40, 40, kernel_size=3, padding=1, bias=False), nn.BatchNorm2d(40), nn.ReLU(), \n",
    "        nn.Upsample(scale_factor=2), nn.Conv2d(40, 40, kernel_size=3, padding=1, bias=False), nn.BatchNorm2d(40), nn.ReLU(), \n",
    "                                     nn.Conv2d(40, 3,  kernel_size=3, padding=1, bias=False),\n",
    "        nn.Sigmoid(), \n",
    "    )\n",
    "\n",
    "    return oDecoder\n",
    "\n",
    "#=============================================================#\n",
    "#=============================================================#\n",
    "torchinfo.summary(GetDecoder(), (32, 2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1694934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d6f5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               --                        --\n",
       "├─Identity: 1-1                          [32, 3, 128, 128]         --\n",
       "├─Sequential: 1-2                        [32, 2]                   --\n",
       "│    └─Identity: 2-1                     [32, 3, 128, 128]         --\n",
       "│    └─Conv2d: 2-2                       [32, 8, 126, 126]         216\n",
       "│    └─BatchNorm2d: 2-3                  [32, 8, 126, 126]         16\n",
       "│    └─ReLU: 2-4                         [32, 8, 126, 126]         --\n",
       "│    └─Conv2d: 2-5                       [32, 16, 124, 124]        1,152\n",
       "│    └─BatchNorm2d: 2-6                  [32, 16, 124, 124]        32\n",
       "│    └─ReLU: 2-7                         [32, 16, 124, 124]        --\n",
       "│    └─MaxPool2d: 2-8                    [32, 16, 62, 62]          --\n",
       "│    └─Conv2d: 2-9                       [32, 32, 60, 60]          4,608\n",
       "│    └─BatchNorm2d: 2-10                 [32, 32, 60, 60]          64\n",
       "│    └─ReLU: 2-11                        [32, 32, 60, 60]          --\n",
       "│    └─Conv2d: 2-12                      [32, 32, 58, 58]          9,216\n",
       "│    └─BatchNorm2d: 2-13                 [32, 32, 58, 58]          64\n",
       "│    └─ReLU: 2-14                        [32, 32, 58, 58]          --\n",
       "│    └─MaxPool2d: 2-15                   [32, 32, 29, 29]          --\n",
       "│    └─Conv2d: 2-16                      [32, 32, 27, 27]          9,216\n",
       "│    └─BatchNorm2d: 2-17                 [32, 32, 27, 27]          64\n",
       "│    └─ReLU: 2-18                        [32, 32, 27, 27]          --\n",
       "│    └─Conv2d: 2-19                      [32, 64, 25, 25]          18,432\n",
       "│    └─BatchNorm2d: 2-20                 [32, 64, 25, 25]          128\n",
       "│    └─ReLU: 2-21                        [32, 64, 25, 25]          --\n",
       "│    └─MaxPool2d: 2-22                   [32, 64, 12, 12]          --\n",
       "│    └─Conv2d: 2-23                      [32, 64, 10, 10]          36,864\n",
       "│    └─BatchNorm2d: 2-24                 [32, 64, 10, 10]          128\n",
       "│    └─ReLU: 2-25                        [32, 64, 10, 10]          --\n",
       "│    └─Conv2d: 2-26                      [32, 64, 8, 8]            36,864\n",
       "│    └─BatchNorm2d: 2-27                 [32, 64, 8, 8]            128\n",
       "│    └─ReLU: 2-28                        [32, 64, 8, 8]            --\n",
       "│    └─MaxPool2d: 2-29                   [32, 64, 4, 4]            --\n",
       "│    └─Conv2d: 2-30                      [32, 64, 2, 2]            36,864\n",
       "│    └─BatchNorm2d: 2-31                 [32, 64, 2, 2]            128\n",
       "│    └─ReLU: 2-32                        [32, 64, 2, 2]            --\n",
       "│    └─MaxPool2d: 2-33                   [32, 64, 1, 1]            --\n",
       "│    └─Conv2d: 2-34                      [32, 2, 1, 1]             130\n",
       "│    └─Flatten: 2-35                     [32, 2]                   --\n",
       "├─Sequential: 1-3                        [32, 3, 128, 128]         --\n",
       "│    └─Identity: 2-36                    [32, 2]                   --\n",
       "│    └─Unflatten: 2-37                   [32, 2, 1, 1]             --\n",
       "│    └─Upsample: 2-38                    [32, 2, 3, 3]             --\n",
       "│    └─Conv2d: 2-39                      [32, 8, 4, 4]             64\n",
       "│    └─BatchNorm2d: 2-40                 [32, 8, 4, 4]             16\n",
       "│    └─ReLU: 2-41                        [32, 8, 4, 4]             --\n",
       "│    └─Upsample: 2-42                    [32, 8, 8, 8]             --\n",
       "│    └─Conv2d: 2-43                      [32, 16, 8, 8]            1,152\n",
       "│    └─BatchNorm2d: 2-44                 [32, 16, 8, 8]            32\n",
       "│    └─ReLU: 2-45                        [32, 16, 8, 8]            --\n",
       "│    └─Upsample: 2-46                    [32, 16, 16, 16]          --\n",
       "│    └─Conv2d: 2-47                      [32, 32, 16, 16]          4,608\n",
       "│    └─BatchNorm2d: 2-48                 [32, 32, 16, 16]          64\n",
       "│    └─ReLU: 2-49                        [32, 32, 16, 16]          --\n",
       "│    └─Upsample: 2-50                    [32, 32, 32, 32]          --\n",
       "│    └─Conv2d: 2-51                      [32, 40, 32, 32]          11,520\n",
       "│    └─BatchNorm2d: 2-52                 [32, 40, 32, 32]          80\n",
       "│    └─ReLU: 2-53                        [32, 40, 32, 32]          --\n",
       "│    └─Upsample: 2-54                    [32, 40, 64, 64]          --\n",
       "│    └─Conv2d: 2-55                      [32, 40, 64, 64]          14,400\n",
       "│    └─BatchNorm2d: 2-56                 [32, 40, 64, 64]          80\n",
       "│    └─ReLU: 2-57                        [32, 40, 64, 64]          --\n",
       "│    └─Upsample: 2-58                    [32, 40, 128, 128]        --\n",
       "│    └─Conv2d: 2-59                      [32, 40, 128, 128]        14,400\n",
       "│    └─BatchNorm2d: 2-60                 [32, 40, 128, 128]        80\n",
       "│    └─ReLU: 2-61                        [32, 40, 128, 128]        --\n",
       "│    └─Conv2d: 2-62                      [32, 3, 128, 128]         1,080\n",
       "│    └─Sigmoid: 2-63                     [32, 3, 128, 128]         --\n",
       "==========================================================================================\n",
       "Total params: 201,890\n",
       "Trainable params: 201,890\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 13.40\n",
       "==========================================================================================\n",
       "Input size (MB): 6.29\n",
       "Forward/backward pass size (MB): 800.78\n",
       "Params size (MB): 0.81\n",
       "Estimated Total Size (MB): 807.88\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GetModel():\n",
    "    oModel = nn.Sequential(\n",
    "        nn.Identity(),\n",
    "        GetEncoder (),\n",
    "        GetDecoder ()\n",
    "    )\n",
    "    return oModel\n",
    "#=============================================================#\n",
    "#=============================================================#\n",
    "torchinfo.summary(GetModel(), (32, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe002e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f559348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def R2Score(vHatY, vY):\n",
    "    vY    = vY   .detach().cpu().view(-1)\n",
    "    vHatY = vHatY.detach().cpu().view(-1)\n",
    "    return r2_score(vY, vHatY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662346bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "831bb4a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 000: | Train loss:  1.389 | Val loss:  1.355 | Train Metric:  0.042 | Val Metric:  0.061 | epoch time: 88.631 | <-- Checkpoint!\n",
      "Epoch 001: | Train loss:  1.361 | Val loss:  1.352 | Train Metric:  0.061 | Val Metric:  0.063 | epoch time: 88.514 | <-- Checkpoint!\n",
      "Epoch 002: | Train loss:  1.357 | Val loss:  1.338 | Train Metric:  0.064 | Val Metric:  0.073 | epoch time: 87.039 | <-- Checkpoint!\n",
      "Epoch 003: | Train loss:  1.352 | Val loss:  1.330 | Train Metric:  0.067 | Val Metric:  0.078 | epoch time: 87.447 | <-- Checkpoint!\n",
      "Epoch 004: | Train loss:  1.348 | Val loss:  1.332 | Train Metric:  0.070 | Val Metric:  0.077 | epoch time: 86.793 |\n",
      "Epoch 005: | Train loss:  1.345 | Val loss:  1.358 | Train Metric:  0.072 | Val Metric:  0.059 | epoch time: 86.902 |\n",
      "Epoch 006: | Train loss:  1.343 | Val loss:  1.331 | Train Metric:  0.074 | Val Metric:  0.078 | epoch time: 87.712 |\n",
      "Epoch 007: | Train loss:  1.339 | Val loss:  1.321 | Train Metric:  0.076 | Val Metric:  0.084 | epoch time: 89.318 | <-- Checkpoint!\n",
      "Epoch 008: | Train loss:  1.336 | Val loss:  1.321 | Train Metric:  0.078 | Val Metric:  0.085 | epoch time: 86.483 | <-- Checkpoint!\n",
      "Epoch 009: | Train loss:  1.333 | Val loss:  1.319 | Train Metric:  0.080 | Val Metric:  0.086 | epoch time: 87.319 | <-- Checkpoint!\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 010: | Train loss:  1.331 | Val loss:  1.317 | Train Metric:  0.081 | Val Metric:  0.087 | epoch time: 86.334 | <-- Checkpoint!\n",
      "Epoch 011: | Train loss:  1.329 | Val loss:  1.318 | Train Metric:  0.083 | Val Metric:  0.087 | epoch time: 86.099 |\n",
      "Epoch 012: | Train loss:  1.327 | Val loss:  1.314 | Train Metric:  0.084 | Val Metric:  0.089 | epoch time: 86.782 | <-- Checkpoint!\n",
      "Epoch 013: | Train loss:  1.325 | Val loss:  1.314 | Train Metric:  0.086 | Val Metric:  0.089 | epoch time: 86.013 |\n",
      "Epoch 014: | Train loss:  1.323 | Val loss:  1.312 | Train Metric:  0.087 | Val Metric:  0.091 | epoch time: 85.967 | <-- Checkpoint!\n",
      "Epoch 015: | Train loss:  1.322 | Val loss:  1.311 | Train Metric:  0.088 | Val Metric:  0.091 | epoch time: 85.915 | <-- Checkpoint!\n",
      "Epoch 016: | Train loss:  1.320 | Val loss:  1.309 | Train Metric:  0.089 | Val Metric:  0.092 | epoch time: 87.348 | <-- Checkpoint!\n",
      "Epoch 017: | Train loss:  1.318 | Val loss:  1.309 | Train Metric:  0.091 | Val Metric:  0.093 | epoch time: 86.019 | <-- Checkpoint!\n",
      "Epoch 018: | Train loss:  1.316 | Val loss:  1.310 | Train Metric:  0.092 | Val Metric:  0.092 | epoch time: 86.756 |\n",
      "Epoch 019: | Train loss:  1.315 | Val loss:  1.308 | Train Metric:  0.093 | Val Metric:  0.094 | epoch time: 87.434 | <-- Checkpoint!\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 020: | Train loss:  1.313 | Val loss:  1.307 | Train Metric:  0.094 | Val Metric:  0.094 | epoch time: 87.980 | <-- Checkpoint!\n",
      "Epoch 021: | Train loss:  1.312 | Val loss:  1.306 | Train Metric:  0.095 | Val Metric:  0.095 | epoch time: 86.827 | <-- Checkpoint!\n",
      "Epoch 022: | Train loss:  1.311 | Val loss:  1.306 | Train Metric:  0.095 | Val Metric:  0.095 | epoch time: 85.825 | <-- Checkpoint!\n",
      "Epoch 023: | Train loss:  1.310 | Val loss:  1.306 | Train Metric:  0.096 | Val Metric:  0.095 | epoch time: 87.831 |\n",
      "Epoch 024: | Train loss:  1.310 | Val loss:  1.306 | Train Metric:  0.096 | Val Metric:  0.095 | epoch time: 86.637 | <-- Checkpoint!\n"
     ]
    }
   ],
   "source": [
    "nEpochs    = 25\n",
    "nIter      = nEpochs * len(oTrainDL)\n",
    "Loss       = nn.MSELoss  ()\n",
    "Metric     = R2Score\n",
    "\n",
    "oModel     = GetModel     ().to(DEVICE)\n",
    "oOptim     = optim.AdamW            (oModel.parameters(), lr=1e-4, betas=(0.9, 0.99), weight_decay=2e-4)\n",
    "oScheduler = OneCycleLR             (oOptim, max_lr=2e-2, total_steps=nIter)\n",
    "\n",
    "\n",
    "lHistory   = TrainModel(oModel, oTrainDL, oTestDL, Loss, Metric, nEpochs, oOptim, oScheduler, Epoch=Epoch, sModelName='AE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949ece2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60a0443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "oModel     = GetModel     ().to(DEVICE)\n",
    "oModel.load_state_dict(torch.load('AE.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdc6292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca5a47dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 970.00 MiB (GPU 0; 3.81 GiB total capacity; 1.32 GiB already allocated; 410.88 MiB free; 1.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m oEncoder \u001b[38;5;241m=\u001b[39m oModel[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 11\u001b[0m     mTrainZ  \u001b[38;5;241m=\u001b[39m \u001b[43moEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmTrainX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     12\u001b[0m     mTestZ   \u001b[38;5;241m=\u001b[39m oEncoder(mTestX\u001b[38;5;241m.\u001b[39mto (DEVICE))\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/OrYair/orYairVenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/OrYair/orYairVenv/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/OrYair/orYairVenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/OrYair/orYairVenv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/OrYair/orYairVenv/lib/python3.8/site-packages/torch/nn/functional.py:2421\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2419\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2422\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2423\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 970.00 MiB (GPU 0; 3.81 GiB total capacity; 1.32 GiB already allocated; 410.88 MiB free; 1.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "K         = 2000\n",
    "oTrainDL2 = torch.utils.data.DataLoader(oTrainSet, shuffle=True, batch_size=K)\n",
    "oTestDL2  = torch.utils.data.DataLoader(oTestSet,  shuffle=True, batch_size=K)\n",
    "\n",
    "mTrainX, vTrainY = next(iter(oTrainDL2))\n",
    "mTestX,  vTestY  = next(iter(oTestDL2))\n",
    "oModel.to(DEVICE)\n",
    "\n",
    "oEncoder = oModel[1]\n",
    "with torch.no_grad():\n",
    "    mTrainZ  = oEncoder(mTrainX.to(DEVICE)).cpu().numpy()\n",
    "    mTestZ   = oEncoder(mTestX.to (DEVICE)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8457685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca84217",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "h1 = ax[0].scatter(mTrainZ[:,0], mTrainZ[:,1], s=50, c=vTrainY, edgecolor='k', cmap='tab10')\n",
    "h2 = ax[1].scatter(mTestZ [:,0], mTestZ [:,1], s=50, c=vTestY,  edgecolor='k', cmap='tab10', vmin=-.5, vmax=9.5)\n",
    "ax[0].set_title   ('Train set')\n",
    "ax[1].set_title   ('Test set')\n",
    "ax[0].axis        ('equal')\n",
    "ax[1].axis        ('equal')\n",
    "ax[0].grid        ()\n",
    "ax[1].grid        ()\n",
    "\n",
    "plt.colorbar    (h2, ticks=range(10))\n",
    "plt.tight_layout()\n",
    "plt.show        ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

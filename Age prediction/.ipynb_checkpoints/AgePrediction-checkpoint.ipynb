{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "146f7472",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:powderblue;\">\n",
    "    <center>\n",
    "         Kaggle\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6d8b6b",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/mariafrenti/age-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b39379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "460a88ea",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:powderblue;\">\n",
    "    <center>\n",
    "         Imports\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5346787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Auto reload:\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9501d5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "169b3bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amitli/OrYair/orYairVenv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from matplotlib                          import pyplot\n",
    "from matplotlib.image                    import imread\n",
    "from torchvision.datasets                import ImageFolder\n",
    "from torch.optim.lr_scheduler            import OneCycleLR\n",
    "from sklearn.metrics                     import r2_score\n",
    "\n",
    "\n",
    "import numpy                  as np\n",
    "import matplotlib.pyplot      as plt\n",
    "import matplotlib.image       as mpimg\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn               as nn\n",
    "import torch.nn.functional    as F\n",
    "import torch.optim            as optim\n",
    "import torchinfo\n",
    "\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import matplotlib\n",
    "import torchvision\n",
    "import torchinfo\n",
    "import gc \n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc8e5c9",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:powderblue;\">\n",
    "    <center>\n",
    "         Load Data\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be9c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FOLDER = \"/home/amitli/Datasets/Age prediction/20-50/train\"\n",
    "TEST_FOLDER  = \"/home/amitli/Datasets/Age prediction/20-50/test\"\n",
    "\n",
    "\n",
    " #-- ImageNet statistics:\n",
    "vMean = np.array([0.48501961, 0.45795686, 0.40760392])\n",
    "vStd  = np.array([0.22899216, 0.224     , 0.225     ])\n",
    "\n",
    "oTransforms = transforms.Compose([\n",
    "    #transforms.Resize    (224),\n",
    "    #transforms.CenterCrop(224),\n",
    "    transforms.ToTensor  (),\n",
    "    transforms.Normalize (mean=vMean, std=vStd),\n",
    "])\n",
    "\n",
    "\n",
    "batchSize            = 32\n",
    "oDataSet             = ImageFolder(root=TRAIN_FOLDER, transform=oTransforms)\n",
    "oTrainSet, oTestSet  = torch.utils.data.random_split(oDataSet, np.round([0.9 * len(oDataSet), 0.1 * len(oDataSet)]).astype(int))\n",
    "\n",
    "oTrainSet.transform  = oTransforms\n",
    "oTestSet .transform  = oTransforms\n",
    "\n",
    "oTrainDL  = torch.utils.data.DataLoader(oTrainSet,   batch_size=batchSize, num_workers=2, persistent_workers=True)\n",
    "oTestDL   = torch.utils.data.DataLoader(oTestSet,    batch_size=batchSize, num_workers=2, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b4133e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e43d444",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:powderblue;\">\n",
    "    <center>\n",
    "         EDA\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(oTrainDL))\n",
    "print (x[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9214bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e6a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(10,3)\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(16, 16))\n",
    "\n",
    "for catgory in range(0,3):\n",
    "    for age in range (20, 30):\n",
    "       \n",
    "        image_age = age + 10*catgory       \n",
    "        img_path  = f\"{TRAIN_FOLDER}/{image_age}/\"\n",
    "        img_file  = random.choice(os.listdir(img_path))\n",
    "        img_fp    = f\"{img_path}/{img_file}\"\n",
    "        img       = mpimg.imread(img_fp)       \n",
    "        axarr[age-20,catgory].imshow(img)\n",
    "        axarr[age-20,catgory].axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48ba985",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:powderblue;\">\n",
    "    <center>\n",
    "         Prepare GPU\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7543e38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f61ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "668f0d2f",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:powderblue;\">\n",
    "    <center>\n",
    "         Transfter Learning (resnet50)\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304038c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c268441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   --                        --\n",
       "├─Conv2d: 1-1                            [32, 64, 64, 64]          (9,408)\n",
       "├─BatchNorm2d: 1-2                       [32, 64, 64, 64]          (128)\n",
       "├─ReLU: 1-3                              [32, 64, 64, 64]          --\n",
       "├─MaxPool2d: 1-4                         [32, 64, 32, 32]          --\n",
       "├─Sequential: 1-5                        [32, 256, 32, 32]         --\n",
       "│    └─Bottleneck: 2-1                   [32, 256, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-1                  [32, 64, 32, 32]          (4,096)\n",
       "│    │    └─BatchNorm2d: 3-2             [32, 64, 32, 32]          (128)\n",
       "│    │    └─ReLU: 3-3                    [32, 64, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-4                  [32, 64, 32, 32]          (36,864)\n",
       "│    │    └─BatchNorm2d: 3-5             [32, 64, 32, 32]          (128)\n",
       "│    │    └─ReLU: 3-6                    [32, 64, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-7                  [32, 256, 32, 32]         (16,384)\n",
       "│    │    └─BatchNorm2d: 3-8             [32, 256, 32, 32]         (512)\n",
       "│    │    └─Sequential: 3-9              [32, 256, 32, 32]         (16,896)\n",
       "│    │    └─ReLU: 3-10                   [32, 256, 32, 32]         --\n",
       "│    └─Bottleneck: 2-2                   [32, 256, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-11                 [32, 64, 32, 32]          (16,384)\n",
       "│    │    └─BatchNorm2d: 3-12            [32, 64, 32, 32]          (128)\n",
       "│    │    └─ReLU: 3-13                   [32, 64, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-14                 [32, 64, 32, 32]          (36,864)\n",
       "│    │    └─BatchNorm2d: 3-15            [32, 64, 32, 32]          (128)\n",
       "│    │    └─ReLU: 3-16                   [32, 64, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-17                 [32, 256, 32, 32]         (16,384)\n",
       "│    │    └─BatchNorm2d: 3-18            [32, 256, 32, 32]         (512)\n",
       "│    │    └─ReLU: 3-19                   [32, 256, 32, 32]         --\n",
       "│    └─Bottleneck: 2-3                   [32, 256, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-20                 [32, 64, 32, 32]          (16,384)\n",
       "│    │    └─BatchNorm2d: 3-21            [32, 64, 32, 32]          (128)\n",
       "│    │    └─ReLU: 3-22                   [32, 64, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-23                 [32, 64, 32, 32]          (36,864)\n",
       "│    │    └─BatchNorm2d: 3-24            [32, 64, 32, 32]          (128)\n",
       "│    │    └─ReLU: 3-25                   [32, 64, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-26                 [32, 256, 32, 32]         (16,384)\n",
       "│    │    └─BatchNorm2d: 3-27            [32, 256, 32, 32]         (512)\n",
       "│    │    └─ReLU: 3-28                   [32, 256, 32, 32]         --\n",
       "├─Sequential: 1-6                        [32, 512, 16, 16]         --\n",
       "│    └─Bottleneck: 2-4                   [32, 512, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-29                 [32, 128, 32, 32]         (32,768)\n",
       "│    │    └─BatchNorm2d: 3-30            [32, 128, 32, 32]         (256)\n",
       "│    │    └─ReLU: 3-31                   [32, 128, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-32                 [32, 128, 16, 16]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-33            [32, 128, 16, 16]         (256)\n",
       "│    │    └─ReLU: 3-34                   [32, 128, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-35                 [32, 512, 16, 16]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-36            [32, 512, 16, 16]         (1,024)\n",
       "│    │    └─Sequential: 3-37             [32, 512, 16, 16]         (132,096)\n",
       "│    │    └─ReLU: 3-38                   [32, 512, 16, 16]         --\n",
       "│    └─Bottleneck: 2-5                   [32, 512, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-39                 [32, 128, 16, 16]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-40            [32, 128, 16, 16]         (256)\n",
       "│    │    └─ReLU: 3-41                   [32, 128, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-42                 [32, 128, 16, 16]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-43            [32, 128, 16, 16]         (256)\n",
       "│    │    └─ReLU: 3-44                   [32, 128, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-45                 [32, 512, 16, 16]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-46            [32, 512, 16, 16]         (1,024)\n",
       "│    │    └─ReLU: 3-47                   [32, 512, 16, 16]         --\n",
       "│    └─Bottleneck: 2-6                   [32, 512, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-48                 [32, 128, 16, 16]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-49            [32, 128, 16, 16]         (256)\n",
       "│    │    └─ReLU: 3-50                   [32, 128, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-51                 [32, 128, 16, 16]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-52            [32, 128, 16, 16]         (256)\n",
       "│    │    └─ReLU: 3-53                   [32, 128, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-54                 [32, 512, 16, 16]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-55            [32, 512, 16, 16]         (1,024)\n",
       "│    │    └─ReLU: 3-56                   [32, 512, 16, 16]         --\n",
       "│    └─Bottleneck: 2-7                   [32, 512, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-57                 [32, 128, 16, 16]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-58            [32, 128, 16, 16]         (256)\n",
       "│    │    └─ReLU: 3-59                   [32, 128, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-60                 [32, 128, 16, 16]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-61            [32, 128, 16, 16]         (256)\n",
       "│    │    └─ReLU: 3-62                   [32, 128, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-63                 [32, 512, 16, 16]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-64            [32, 512, 16, 16]         (1,024)\n",
       "│    │    └─ReLU: 3-65                   [32, 512, 16, 16]         --\n",
       "├─Sequential: 1-7                        [32, 1024, 8, 8]          --\n",
       "│    └─Bottleneck: 2-8                   [32, 1024, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-66                 [32, 256, 16, 16]         (131,072)\n",
       "│    │    └─BatchNorm2d: 3-67            [32, 256, 16, 16]         (512)\n",
       "│    │    └─ReLU: 3-68                   [32, 256, 16, 16]         --\n",
       "│    │    └─Conv2d: 3-69                 [32, 256, 8, 8]           (589,824)\n",
       "│    │    └─BatchNorm2d: 3-70            [32, 256, 8, 8]           (512)\n",
       "│    │    └─ReLU: 3-71                   [32, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-72                 [32, 1024, 8, 8]          (262,144)\n",
       "│    │    └─BatchNorm2d: 3-73            [32, 1024, 8, 8]          (2,048)\n",
       "│    │    └─Sequential: 3-74             [32, 1024, 8, 8]          (526,336)\n",
       "│    │    └─ReLU: 3-75                   [32, 1024, 8, 8]          --\n",
       "│    └─Bottleneck: 2-9                   [32, 1024, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-76                 [32, 256, 8, 8]           (262,144)\n",
       "│    │    └─BatchNorm2d: 3-77            [32, 256, 8, 8]           (512)\n",
       "│    │    └─ReLU: 3-78                   [32, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-79                 [32, 256, 8, 8]           (589,824)\n",
       "│    │    └─BatchNorm2d: 3-80            [32, 256, 8, 8]           (512)\n",
       "│    │    └─ReLU: 3-81                   [32, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-82                 [32, 1024, 8, 8]          (262,144)\n",
       "│    │    └─BatchNorm2d: 3-83            [32, 1024, 8, 8]          (2,048)\n",
       "│    │    └─ReLU: 3-84                   [32, 1024, 8, 8]          --\n",
       "│    └─Bottleneck: 2-10                  [32, 1024, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-85                 [32, 256, 8, 8]           (262,144)\n",
       "│    │    └─BatchNorm2d: 3-86            [32, 256, 8, 8]           (512)\n",
       "│    │    └─ReLU: 3-87                   [32, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-88                 [32, 256, 8, 8]           (589,824)\n",
       "│    │    └─BatchNorm2d: 3-89            [32, 256, 8, 8]           (512)\n",
       "│    │    └─ReLU: 3-90                   [32, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-91                 [32, 1024, 8, 8]          (262,144)\n",
       "│    │    └─BatchNorm2d: 3-92            [32, 1024, 8, 8]          (2,048)\n",
       "│    │    └─ReLU: 3-93                   [32, 1024, 8, 8]          --\n",
       "│    └─Bottleneck: 2-11                  [32, 1024, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-94                 [32, 256, 8, 8]           (262,144)\n",
       "│    │    └─BatchNorm2d: 3-95            [32, 256, 8, 8]           (512)\n",
       "│    │    └─ReLU: 3-96                   [32, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-97                 [32, 256, 8, 8]           (589,824)\n",
       "│    │    └─BatchNorm2d: 3-98            [32, 256, 8, 8]           (512)\n",
       "│    │    └─ReLU: 3-99                   [32, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-100                [32, 1024, 8, 8]          (262,144)\n",
       "│    │    └─BatchNorm2d: 3-101           [32, 1024, 8, 8]          (2,048)\n",
       "│    │    └─ReLU: 3-102                  [32, 1024, 8, 8]          --\n",
       "│    └─Bottleneck: 2-12                  [32, 1024, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-103                [32, 256, 8, 8]           (262,144)\n",
       "│    │    └─BatchNorm2d: 3-104           [32, 256, 8, 8]           (512)\n",
       "│    │    └─ReLU: 3-105                  [32, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-106                [32, 256, 8, 8]           (589,824)\n",
       "│    │    └─BatchNorm2d: 3-107           [32, 256, 8, 8]           (512)\n",
       "│    │    └─ReLU: 3-108                  [32, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-109                [32, 1024, 8, 8]          (262,144)\n",
       "│    │    └─BatchNorm2d: 3-110           [32, 1024, 8, 8]          (2,048)\n",
       "│    │    └─ReLU: 3-111                  [32, 1024, 8, 8]          --\n",
       "│    └─Bottleneck: 2-13                  [32, 1024, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-112                [32, 256, 8, 8]           (262,144)\n",
       "│    │    └─BatchNorm2d: 3-113           [32, 256, 8, 8]           (512)\n",
       "│    │    └─ReLU: 3-114                  [32, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-115                [32, 256, 8, 8]           (589,824)\n",
       "│    │    └─BatchNorm2d: 3-116           [32, 256, 8, 8]           (512)\n",
       "│    │    └─ReLU: 3-117                  [32, 256, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-118                [32, 1024, 8, 8]          (262,144)\n",
       "│    │    └─BatchNorm2d: 3-119           [32, 1024, 8, 8]          (2,048)\n",
       "│    │    └─ReLU: 3-120                  [32, 1024, 8, 8]          --\n",
       "├─Sequential: 1-8                        [32, 2048, 4, 4]          --\n",
       "│    └─Bottleneck: 2-14                  [32, 2048, 4, 4]          --\n",
       "│    │    └─Conv2d: 3-121                [32, 512, 8, 8]           (524,288)\n",
       "│    │    └─BatchNorm2d: 3-122           [32, 512, 8, 8]           (1,024)\n",
       "│    │    └─ReLU: 3-123                  [32, 512, 8, 8]           --\n",
       "│    │    └─Conv2d: 3-124                [32, 512, 4, 4]           (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-125           [32, 512, 4, 4]           (1,024)\n",
       "│    │    └─ReLU: 3-126                  [32, 512, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-127                [32, 2048, 4, 4]          (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-128           [32, 2048, 4, 4]          (4,096)\n",
       "│    │    └─Sequential: 3-129            [32, 2048, 4, 4]          (2,101,248)\n",
       "│    │    └─ReLU: 3-130                  [32, 2048, 4, 4]          --\n",
       "│    └─Bottleneck: 2-15                  [32, 2048, 4, 4]          --\n",
       "│    │    └─Conv2d: 3-131                [32, 512, 4, 4]           (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-132           [32, 512, 4, 4]           (1,024)\n",
       "│    │    └─ReLU: 3-133                  [32, 512, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-134                [32, 512, 4, 4]           (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-135           [32, 512, 4, 4]           (1,024)\n",
       "│    │    └─ReLU: 3-136                  [32, 512, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-137                [32, 2048, 4, 4]          (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-138           [32, 2048, 4, 4]          (4,096)\n",
       "│    │    └─ReLU: 3-139                  [32, 2048, 4, 4]          --\n",
       "│    └─Bottleneck: 2-16                  [32, 2048, 4, 4]          --\n",
       "│    │    └─Conv2d: 3-140                [32, 512, 4, 4]           (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-141           [32, 512, 4, 4]           (1,024)\n",
       "│    │    └─ReLU: 3-142                  [32, 512, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-143                [32, 512, 4, 4]           (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-144           [32, 512, 4, 4]           (1,024)\n",
       "│    │    └─ReLU: 3-145                  [32, 512, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-146                [32, 2048, 4, 4]          (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-147           [32, 2048, 4, 4]          (4,096)\n",
       "│    │    └─ReLU: 3-148                  [32, 2048, 4, 4]          --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [32, 2048, 1, 1]          --\n",
       "├─Sequential: 1-10                       [32, 1]                   --\n",
       "│    └─Linear: 2-17                      [32, 512]                 1,049,088\n",
       "│    └─ReLU: 2-18                        [32, 512]                 --\n",
       "│    └─Linear: 2-19                      [32, 256]                 131,328\n",
       "│    └─ReLU: 2-20                        [32, 256]                 --\n",
       "│    └─Linear: 2-21                      [32, 128]                 32,896\n",
       "│    └─ReLU: 2-22                        [32, 128]                 --\n",
       "│    └─Linear: 2-23                      [32, 1]                   129\n",
       "==========================================================================================\n",
       "Total params: 24,721,473\n",
       "Trainable params: 1,213,441\n",
       "Non-trainable params: 23,508,032\n",
       "Total mult-adds (G): 42.75\n",
       "==========================================================================================\n",
       "Input size (MB): 6.29\n",
       "Forward/backward pass size (MB): 1858.31\n",
       "Params size (MB): 98.89\n",
       "Estimated Total Size (MB): 1963.48\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GetPretrainedModel():\n",
    "    oModel = torchvision.models.resnet50(pretrained=True)\n",
    "    #-- freeze weights:\n",
    "    for mParam in oModel.parameters():\n",
    "        if False == isinstance(mParam, nn.BatchNorm2d):\n",
    "            mParam.requires_grad = False\n",
    "        \n",
    "    #-- Replace classifier head:\n",
    "    dIn       = oModel.fc.in_features\n",
    "    oModel.fc = nn.Sequential(\n",
    "        nn.Linear(dIn, 512), nn.ReLU(),\n",
    "        nn.Linear(512, 256), nn.ReLU(),\n",
    "        nn.Linear(256, 128), nn.ReLU(),\n",
    "        #nn.Linear(128, 31)\n",
    "        nn.Linear(128, 1)\n",
    "    )\n",
    "    \n",
    "    return oModel\n",
    "\n",
    "torchinfo.summary(GetPretrainedModel(), (32, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614cb27c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b93ba5e",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:powderblue;\">\n",
    "    <center>\n",
    "         Train and Epoc codes\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955833bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "778a78fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def R2Score(vHatY, vY):\n",
    "    vY    = vY   .detach().cpu().view(-1)\n",
    "    vHatY = vHatY.detach().cpu().view(-1)\n",
    "    return r2_score(vY, vHatY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9455838a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06df5b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(mScore, vY):\n",
    "    vHatY = mScore.detach().argmax(dim=1)\n",
    "    return (vHatY == vY).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96335a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a70cbb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Epoch(oModel, oDataDL, Loss, Metric, oOptim=None, oScheduler=None, bTrain=True):\n",
    "\n",
    "    epochLoss   = 0\n",
    "    epochMetric = 0\n",
    "    count       = 0\n",
    "    nIter       = len(oDataDL)\n",
    "    vLR         = np.full(nIter, np.nan)\n",
    "    DEVICE      = next(oModel.parameters()).device #-- CPU\\GPU\n",
    "\n",
    "\n",
    "    oModel.train(bTrain) #-- train or test\n",
    "\n",
    "    #-- Iterate over the mini-batches:\n",
    "    for ii, (mX, vY) in enumerate(oDataDL):\n",
    "        #-- Move to device (CPU\\GPU):\n",
    "        mX = mX.to(DEVICE)\n",
    "        vY = vY.to(DEVICE)\n",
    "                \n",
    "        #-- Forward:\n",
    "        if bTrain == True:\n",
    "            #-- Store computational graph:\n",
    "            mZ   = oModel(mX)                        \n",
    "            loss = Loss(mZ, vY)           \n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                #-- Do not store computational graph:\n",
    "                mZ   = oModel(mX)                \n",
    "                loss = Loss(mZ, vY)\n",
    "\n",
    "        #-- Backward:\n",
    "        if bTrain == True:\n",
    "            oOptim.zero_grad() #-- set gradients to zeros\n",
    "            loss.backward()    #-- backward\n",
    "            oOptim.step()      #-- update parameters\n",
    "            if oScheduler is not None:\n",
    "                vLR[ii] = oScheduler.get_last_lr()[0]\n",
    "                oScheduler.step() #-- update learning rate\n",
    "\n",
    "        Nb           = vY.shape[0]\n",
    "        count       += Nb\n",
    "        epochLoss   += Nb * loss.item()\n",
    "        epochMetric += Nb * Metric(mZ, vY)\n",
    "        print(f'\\r{\"Train\" if bTrain else \"Val\"} - Iteration: {ii:3d} ({nIter}): loss = {loss:2.6f}', end='')\n",
    "\n",
    "    print('', end='\\r')\n",
    "    epochLoss   /= count\n",
    "    epochMetric /= count\n",
    "\n",
    "    return epochLoss, epochMetric, vLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd76eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd99409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# AUTO ENCODER\n",
    "#\n",
    "\n",
    "def Epoch(oModel, oDataDL, Loss, Metric, oOptim=None, oScheduler=None, bTrain=True):\n",
    "\n",
    "    epochLoss   = 0\n",
    "    epochMetric = 0\n",
    "    count       = 0\n",
    "    nIter       = len(oDataDL)\n",
    "    vLR         = np.full(nIter, np.nan)\n",
    "    DEVICE      = next(oModel.parameters()).device #-- CPU\\GPU\n",
    "\n",
    "    oModel.train(bTrain) #-- train or test\n",
    "\n",
    "    #-- Iterate over the mini-batches:\n",
    "    for ii, (mX, _) in enumerate(oDataDL):\n",
    "        #-- Move to device (CPU\\GPU):\n",
    "        mX = mX.to(DEVICE)\n",
    "\n",
    "        if bTrain == True:\n",
    "            #-- Forward:\n",
    "            mHatX = oModel(mX)\n",
    "            loss  = Loss  (mHatX, mX)\n",
    "                    \n",
    "            #-- Backward:\n",
    "            vLR[ii] = oScheduler.get_last_lr()[0]\n",
    "            oOptim    .zero_grad() #-- set gradients to zeros\n",
    "            loss      .backward () #-- backward\n",
    "            oOptim    .step     () #-- update parameters\n",
    "            oScheduler.step     () #-- update learning rate\n",
    "\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                #-- Forward:\n",
    "                mHatX = oModel(mX)\n",
    "                loss  = Loss  (mHatX, mX)\n",
    "\n",
    "        Nb           = mX.shape[0]\n",
    "        count       += Nb\n",
    "        epochLoss   += Nb * loss.item()\n",
    "        epochMetric += Nb * Metric(mHatX, mX)\n",
    "        print(f'\\r{\"Train\" if bTrain else \"Val\"} - Iteration: {ii:3d} ({nIter}): loss = {loss:2.6f}', end='')\n",
    "\n",
    "    print('', end='\\r')\n",
    "    epochLoss   /= count\n",
    "    epochMetric /= count\n",
    "\n",
    "    return epochLoss, epochMetric, vLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b0afc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b77b6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(oModel, oTrainData, oValData, Loss, Metric, nEpochs, oOptim, oScheduler=None, Epoch=Epoch, sModelName='BestParams'):\n",
    "\n",
    "    vTrainLoss   = np.full(nEpochs, np.nan)\n",
    "    vTrainMetric = np.full(nEpochs, np.nan)\n",
    "    vValLoss     = np.full(nEpochs, np.nan)\n",
    "    vValMetric   = np.full(nEpochs, np.nan)\n",
    "    vLR          = np.full(0,       np.nan)\n",
    "    bestMetric   = -float('inf')\n",
    "\n",
    "    for epoch in range(nEpochs):\n",
    "        startTime                    = time.time()\n",
    "        trainLoss, trainMetric, vLRi = Epoch(oModel, oTrainData, Loss, Metric, oOptim, oScheduler, bTrain=True ) #-- train\n",
    "        valLoss,   valMetric,   _    = Epoch(oModel, oValData,   Loss, Metric,                     bTrain=False) #-- validate\n",
    "        epochTime                    = time.time() - startTime\n",
    "\n",
    "        #-- Display:\n",
    "        if epoch % 10 == 0:\n",
    "            print('-' * 120)\n",
    "        print('Epoch '            f'{epoch       :03d}:',   end='')\n",
    "        print(' | Train loss: '   f'{trainLoss   :6.3f}',   end='')\n",
    "        print(' | Val loss: '     f'{valLoss     :6.3f}',   end='')\n",
    "        print(' | Train Metric: ' f'{trainMetric :6.3f}',   end='')\n",
    "        print(' | Val Metric: '   f'{valMetric   :6.3f}',   end='')\n",
    "        print(' | epoch time: '   f'{epochTime   :6.3f} |', end='')\n",
    "\n",
    "        vTrainLoss  [epoch] = trainLoss\n",
    "        vTrainMetric[epoch] = trainMetric\n",
    "        vValLoss    [epoch] = valLoss\n",
    "        vValMetric  [epoch] = valMetric\n",
    "        vLR                 = np.concatenate([vLR, vLRi])\n",
    "\n",
    "        #-- Save best model (early stopping):\n",
    "        if valMetric > bestMetric:\n",
    "            bestMetric = valMetric\n",
    "            try   : torch.save(oModel.state_dict(), sModelName + '.pt')\n",
    "            except: pass\n",
    "            print(' <-- Checkpoint!')\n",
    "        else:\n",
    "            print('')\n",
    "\n",
    "    #-- Load best model (early stopping):\n",
    "    oModel.load_state_dict(torch.load(sModelName + '.pt'))\n",
    "\n",
    "    return vTrainLoss, vTrainMetric, vValLoss, vValMetric, vLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07871a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07cc4732",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:powderblue;\">\n",
    "    <center>\n",
    "         Train (Transfer learning model)\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d8b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "nEpochs    = 20\n",
    "nIter      = nEpochs * len(oTrainDL)\n",
    "Loss       = nn.CrossEntropyLoss()\n",
    "oModel     = GetPretrainedModel     ().to(DEVICE)\n",
    "oOptim     = optim.AdamW            (oModel.parameters(), lr=1e-4, betas=(0.9, 0.99), weight_decay=2e-4)\n",
    "oScheduler = OneCycleLR             (oOptim, max_lr=2e-2, total_steps=nIter)\n",
    "lHistory   = TrainClassficationModel(oModel, oTrainDL, oTestDL, Loss, nEpochs, oOptim, oScheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1203a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ba25227",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:powderblue;\">\n",
    "    <center>\n",
    "         AutoEncoder\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53304777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a36765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetEncoder():\n",
    "    oEncoder = nn.Sequential(\n",
    "        nn.Identity(),\n",
    "        nn.Conv2d(3,  8,  kernel_size=3, bias=False), nn.BatchNorm2d(8 ), nn.ReLU(), \n",
    "        nn.Conv2d(8,  16, kernel_size=3, bias=False), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        nn.Conv2d(16, 32, kernel_size=3, bias=False), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "        nn.Conv2d(32, 32, kernel_size=3, bias=False), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        nn.Conv2d(32, 32, kernel_size=3, bias=False), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "        nn.Conv2d(32, 64, kernel_size=3, bias=False), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        nn.Conv2d(64, 64, kernel_size=3, bias=False), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "        nn.Conv2d(64, 64, kernel_size=3, bias=False), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        nn.Conv2d(64, 64, kernel_size=3, bias=False), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        nn.Conv2d(64, 2,  kernel_size=1), \n",
    "        nn.Flatten()\n",
    "    )\n",
    "    \n",
    "    return oEncoder\n",
    "#=============================================================#\n",
    "#=============================================================#\n",
    "#torchinfo.summary(GetEncoder(), (32, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b5611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDecoder():\n",
    "    oDecoder = nn.Sequential(\n",
    "        nn.Identity(),\n",
    "        nn.Unflatten(1, (2, 1, 1)),\n",
    "        nn.Upsample(scale_factor=3), nn.Conv2d(2,  8,  kernel_size=2, padding=1, bias=False), nn.BatchNorm2d(8 ), nn.ReLU(), \n",
    "        nn.Upsample(scale_factor=2), nn.Conv2d(8,  16, kernel_size=3, padding=1, bias=False), nn.BatchNorm2d(16), nn.ReLU(), \n",
    "        nn.Upsample(scale_factor=2), nn.Conv2d(16, 32, kernel_size=3, padding=1, bias=False), nn.BatchNorm2d(32), nn.ReLU(), \n",
    "        nn.Upsample(scale_factor=2), nn.Conv2d(32, 40, kernel_size=3, padding=1, bias=False), nn.BatchNorm2d(40), nn.ReLU(), \n",
    "        nn.Upsample(scale_factor=2), nn.Conv2d(40, 40, kernel_size=3, padding=1, bias=False), nn.BatchNorm2d(40), nn.ReLU(), \n",
    "        nn.Upsample(scale_factor=2), nn.Conv2d(40, 40, kernel_size=3, padding=1, bias=False), nn.BatchNorm2d(40), nn.ReLU(), \n",
    "                                     nn.Conv2d(40, 3,  kernel_size=3, padding=1, bias=False),\n",
    "        nn.Sigmoid(), \n",
    "    )\n",
    "\n",
    "    return oDecoder\n",
    "\n",
    "#=============================================================#\n",
    "#=============================================================#\n",
    "#torchinfo.summary(GetDecoder(), (32, 2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1694934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d6f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetModel():\n",
    "    oModel = nn.Sequential(\n",
    "        nn.Identity(),\n",
    "        GetEncoder (),\n",
    "        GetDecoder ()\n",
    "    )\n",
    "    return oModel\n",
    "#=============================================================#\n",
    "#=============================================================#\n",
    "torchinfo.summary(GetModel(), (32, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42769f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b997dcf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdffccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d10b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6721c8c",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:powderblue;\">\n",
    "    <center>\n",
    "         Train (AE Model)\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ba2ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nEpochs    = 25\n",
    "nIter      = nEpochs * len(oTrainDL)\n",
    "Loss       = nn.MSELoss  ()\n",
    "Metric     = R2Score\n",
    "\n",
    "oModel     = GetModel     ().to(DEVICE)\n",
    "oOptim     = optim.AdamW            (oModel.parameters(), lr=1e-4, betas=(0.9, 0.99), weight_decay=2e-4)\n",
    "oScheduler = OneCycleLR             (oOptim, max_lr=2e-2, total_steps=nIter)\n",
    "\n",
    "\n",
    "lHistory   = TrainModel(oModel, oTrainDL, oTestDL, Loss, Metric, nEpochs, oOptim, oScheduler, Epoch=Epoch, sModelName='AE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84fc303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e75b3be",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:powderblue;\">\n",
    "    <center>\n",
    "         Visualize Encoder Results (Change to 3 categories, instead of 30)\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee79a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba28fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "oModel     = GetModel     ().to(DEVICE)\n",
    "oModel.load_state_dict(torch.load('AE.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46091ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f3463d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c112f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "K         = 200\n",
    "oTrainDL2 = torch.utils.data.DataLoader(oTrainSet, shuffle=True, batch_size=K)\n",
    "oTestDL2  = torch.utils.data.DataLoader(oTestSet,  shuffle=True, batch_size=K)\n",
    "\n",
    "mTrainX, vTrainY = next(iter(oTrainDL2))\n",
    "mTestX,  vTestY  = next(iter(oTestDL2))\n",
    "oModel.to(DEVICE)\n",
    "\n",
    "oEncoder = oModel[1]\n",
    "with torch.no_grad():\n",
    "    mTrainZ  = oEncoder(mTrainX.to(DEVICE)).cpu().numpy()\n",
    "    mTestZ   = oEncoder(mTestX.to (DEVICE)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df0d442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35497391",
   "metadata": {},
   "outputs": [],
   "source": [
    "vTmpTrainY = vTrainY.tolist().copy()\n",
    "vTmpTestY  = vTestY.tolist().copy()\n",
    "\n",
    "for i in range(len(vTmpTrainY)):\n",
    "    vTmpTrainY[i] = int((vTmpTrainY[i]) / 10)\n",
    "\n",
    "for i in range(len(vTmpTestY)):\n",
    "    vTmpTestY[i] = int((vTmpTestY[i]) / 10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0755d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(vTmpTrainY), max(vTmpTestY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faffc21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4413bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "h1 = ax[0].scatter(mTrainZ[:,0], mTrainZ[:,1], s=50, c=vTmpTrainY, edgecolor='k')\n",
    "h2 = ax[1].scatter(mTestZ [:,0], mTestZ [:,1], s=50, c=vTmpTestY,  edgecolor='k')\n",
    "ax[0].set_title   ('Train set')\n",
    "ax[1].set_title   ('Test set')\n",
    "ax[0].axis        ('equal')\n",
    "ax[1].axis        ('equal')\n",
    "ax[0].grid        ()\n",
    "ax[1].grid        ()\n",
    "\n",
    "plt.colorbar    (h2, ticks=range(10))\n",
    "plt.tight_layout()\n",
    "plt.show        ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268168a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3de3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8e77fb8",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:Orange;\">\n",
    "    <center>\n",
    "         We can train and test with R2 (MSE) - how much we are close to real age\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9433777f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b01d713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def GetRegressionModel():\n",
    "#     oModel = nn.Sequential(\n",
    "#         nn.Identity(),\n",
    "#         nn.Flatten          (),\n",
    "#         nn.Linear           (49152, 10),\n",
    "#         nn.Linear           (10, 1),\n",
    "#     )\n",
    "    \n",
    "#     return oModel\n",
    "\n",
    "\n",
    "# Loss   = nn.MSELoss  ()\n",
    "# DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# model  = GetRegressionModel     ().to(DEVICE)\n",
    "# oOptim = optim.AdamW            (model.parameters(), lr=1e-4, betas=(0.9, 0.99), weight_decay=2e-4)\n",
    "\n",
    "# model.train(True) \n",
    "\n",
    "# x, y = next(iter(oTrainDL))\n",
    "# x    = x.to(DEVICE)\n",
    "# y    = y.type(torch.FloatTensor)\n",
    "# y    = y.to(DEVICE)\n",
    "\n",
    "\n",
    "# hatX = model(x)\n",
    "# hatX = hatX.squeeze()\n",
    "\n",
    "\n",
    "# loss = Loss  (hatX, y)\n",
    "\n",
    "# oOptim.zero_grad() \n",
    "\n",
    "# print(f\"x: {x.shape}, y: {y.shape}, hatX: {hatX.shape}\")\n",
    "# print(f\"x: {x.dtype}, y: {y.dtype}, hatX: {hatX.dtype}\")\n",
    "# loss.backward()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175d8a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59105fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Epoch(oModel, oDataDL, Loss, Metric, oOptim=None, oScheduler=None, bTrain=True):\n",
    "\n",
    "    epochLoss   = 0\n",
    "    epochMetric = 0\n",
    "    count       = 0\n",
    "    nIter       = len(oDataDL)\n",
    "    vLR         = np.full(nIter, np.nan)\n",
    "    DEVICE      = next(oModel.parameters()).device #-- CPU\\GPU\n",
    "\n",
    "\n",
    "    oModel.train(bTrain) #-- train or test\n",
    "\n",
    "    #-- Iterate over the mini-batches:\n",
    "    for ii, (mX, vY) in enumerate(oDataDL):\n",
    "        #-- Move to device (CPU\\GPU):\n",
    "        mX = mX.to(DEVICE)\n",
    "        vY = vY.type(torch.FloatTensor)\n",
    "        vY = vY.to(DEVICE)\n",
    "                \n",
    "        #-- Forward:\n",
    "        if bTrain == True:\n",
    "            #-- Store computational graph:\n",
    "            mZ   = oModel(mX)        \n",
    "            mZ   = mZ.squeeze()            \n",
    "            loss = Loss(mZ, vY)     \n",
    "           \n",
    "        else:\n",
    "           \n",
    "            with torch.no_grad():\n",
    "                #-- Do not store computational graph:\n",
    "                mZ   = oModel(mX)\n",
    "                mZ   = mZ.squeeze()\n",
    "                loss = Loss(mZ, vY)\n",
    "\n",
    "        #-- Backward:\n",
    "        if bTrain == True:\n",
    "            oOptim.zero_grad() #-- set gradients to zeros           \n",
    "            loss.backward()    #-- backward\n",
    "            oOptim.step()      #-- update parameters\n",
    "            if oScheduler is not None:\n",
    "                vLR[ii] = oScheduler.get_last_lr()[0]\n",
    "                oScheduler.step() #-- update learning rate\n",
    "\n",
    "        Nb           = vY.shape[0]\n",
    "        count       += Nb\n",
    "        epochLoss   += Nb * loss.item()\n",
    "        epochMetric += Nb * Metric(mZ, vY)\n",
    "        print(f'\\r{\"Train\" if bTrain else \"Val\"} - Iteration: {ii:3d} ({nIter}): loss = {loss:2.6f}', end='')\n",
    "\n",
    "    print('', end='\\r')\n",
    "    epochLoss   /= count\n",
    "    epochMetric /= count\n",
    "\n",
    "    return epochLoss, epochMetric, vLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c291c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d58c6bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 000: | Train loss: 76.347 | Val loss: 71.020 | Train Metric:  0.004 | Val Metric:  0.086 | epoch time: 53.518 | <-- Checkpoint!\n",
      "Epoch 001: | Train loss: 71.615 | Val loss: 70.336 | Train Metric:  0.068 | Val Metric:  0.095 | epoch time: 54.139 | <-- Checkpoint!\n",
      "Epoch 002: | Train loss: 71.405 | Val loss: 71.372 | Train Metric:  0.072 | Val Metric:  0.082 | epoch time: 53.535 |\n",
      "Epoch 003: | Train loss: 70.883 | Val loss: 71.842 | Train Metric:  0.079 | Val Metric:  0.075 | epoch time: 53.163 |\n",
      "Epoch 004: | Train loss: 69.684 | Val loss: 73.928 | Train Metric:  0.094 | Val Metric:  0.047 | epoch time: 52.624 |\n",
      "Epoch 005: | Train loss: 69.067 | Val loss: 72.685 | Train Metric:  0.102 | Val Metric:  0.063 | epoch time: 53.351 |\n",
      "Epoch 006: | Train loss: 68.311 | Val loss: 71.571 | Train Metric:  0.112 | Val Metric:  0.078 | epoch time: 51.723 |\n",
      "Epoch 007: | Train loss: 67.596 | Val loss: 70.820 | Train Metric:  0.121 | Val Metric:  0.088 | epoch time: 50.628 |\n",
      "Epoch 008: | Train loss: 67.191 | Val loss: 68.349 | Train Metric:  0.127 | Val Metric:  0.121 | epoch time: 50.351 | <-- Checkpoint!\n",
      "Epoch 009: | Train loss: 66.605 | Val loss: 68.788 | Train Metric:  0.133 | Val Metric:  0.115 | epoch time: 50.373 |\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 010: | Train loss: 66.037 | Val loss: 68.595 | Train Metric:  0.141 | Val Metric:  0.117 | epoch time: 49.768 |\n",
      "Epoch 011: | Train loss: 65.924 | Val loss: 72.371 | Train Metric:  0.142 | Val Metric:  0.067 | epoch time: 49.798 |\n",
      "Epoch 012: | Train loss: 64.867 | Val loss: 71.917 | Train Metric:  0.156 | Val Metric:  0.074 | epoch time: 49.998 |\n",
      "Epoch 013: | Train loss: 64.055 | Val loss: 70.172 | Train Metric:  0.166 | Val Metric:  0.096 | epoch time: 50.025 |\n",
      "Epoch 014: | Train loss: 63.216 | Val loss: 69.470 | Train Metric:  0.177 | Val Metric:  0.105 | epoch time: 49.783 |\n",
      "Epoch 015: | Train loss: 62.569 | Val loss: 69.366 | Train Metric:  0.185 | Val Metric:  0.107 | epoch time: 50.560 |\n",
      "Epoch 016: | Train loss: 61.711 | Val loss: 69.923 | Train Metric:  0.196 | Val Metric:  0.099 | epoch time: 52.093 |\n",
      "Epoch 017: | Train loss: 61.057 | Val loss: 69.977 | Train Metric:  0.204 | Val Metric:  0.098 | epoch time: 51.560 |\n",
      "Epoch 018: | Train loss: 59.916 | Val loss: 74.392 | Train Metric:  0.219 | Val Metric:  0.040 | epoch time: 52.432 |\n",
      "Epoch 019: | Train loss: 59.257 | Val loss: 72.391 | Train Metric:  0.228 | Val Metric:  0.066 | epoch time: 52.192 |\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 020: | Train loss: 58.677 | Val loss: 73.800 | Train Metric:  0.235 | Val Metric:  0.047 | epoch time: 52.969 |\n",
      "Epoch 021: | Train loss: 58.388 | Val loss: 72.689 | Train Metric:  0.239 | Val Metric:  0.061 | epoch time: 52.527 |\n",
      "Epoch 022: | Train loss: 57.973 | Val loss: 72.894 | Train Metric:  0.244 | Val Metric:  0.058 | epoch time: 53.021 |\n",
      "Epoch 023: | Train loss: 57.563 | Val loss: 72.485 | Train Metric:  0.250 | Val Metric:  0.064 | epoch time: 51.928 |\n",
      "Epoch 024: | Train loss: 56.937 | Val loss: 73.086 | Train Metric:  0.258 | Val Metric:  0.056 | epoch time: 52.334 |\n",
      "Epoch 025: | Train loss: 56.717 | Val loss: 71.769 | Train Metric:  0.260 | Val Metric:  0.074 | epoch time: 50.836 |\n",
      "Epoch 026: | Train loss: 56.370 | Val loss: 71.395 | Train Metric:  0.265 | Val Metric:  0.079 | epoch time: 51.356 |\n",
      "Epoch 027: | Train loss: 56.152 | Val loss: 70.994 | Train Metric:  0.267 | Val Metric:  0.085 | epoch time: 52.287 |\n",
      "Epoch 028: | Train loss: 55.895 | Val loss: 71.385 | Train Metric:  0.271 | Val Metric:  0.079 | epoch time: 52.261 |\n",
      "Epoch 029: | Train loss: 55.692 | Val loss: 71.683 | Train Metric:  0.274 | Val Metric:  0.075 | epoch time: 52.196 |\n"
     ]
    }
   ],
   "source": [
    "nEpochs    = 30\n",
    "nIter      = nEpochs * len(oTrainDL)\n",
    "Loss       = nn.MSELoss  ()\n",
    "Metric     = R2Score\n",
    "\n",
    "oModel     = GetPretrainedModel     ().to(DEVICE)\n",
    "oOptim     = optim.AdamW            (oModel.parameters(), lr=1e-4, betas=(0.9, 0.99), weight_decay=2e-4)\n",
    "oScheduler = OneCycleLR             (oOptim, max_lr=2e-2, total_steps=nIter)\n",
    "\n",
    "\n",
    "lHistory   = TrainModel(oModel, oTrainDL, oTestDL, Loss, Metric, nEpochs, oOptim, oScheduler, Epoch=Epoch, sModelName='AE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97ada3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6eaf9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "443e7923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: 20, yHat: 15, diff:   5\n",
      "y: 23, yHat: 17, diff:   6\n",
      "y: 20, yHat: 13, diff:   7\n",
      "y:  6, yHat: 10, diff:   4\n",
      "y: 15, yHat: 10, diff:   5\n",
      "y:  5, yHat: 12, diff:   7\n",
      "y: 11, yHat: 13, diff:   2\n",
      "y:  0, yHat: 11, diff:  11\n",
      "y: 16, yHat:  9, diff:   7\n",
      "y: 28, yHat: 15, diff:  13\n",
      "y:  5, yHat: 15, diff:  10\n",
      "y:  6, yHat: 11, diff:   5\n",
      "y: 12, yHat: 11, diff:   1\n",
      "y: 27, yHat: 20, diff:   7\n",
      "y: 17, yHat: 12, diff:   5\n",
      "y:  1, yHat: 11, diff:  10\n",
      "y:  3, yHat:  9, diff:   6\n",
      "y: 16, yHat: 10, diff:   6\n",
      "y: 11, yHat: 16, diff:   5\n",
      "y:  4, yHat:  8, diff:   4\n",
      "y: 20, yHat: 17, diff:   3\n",
      "y: 19, yHat: 24, diff:   5\n",
      "y: 23, yHat: 16, diff:   7\n",
      "y:  0, yHat: 10, diff:  10\n",
      "y: 20, yHat: 14, diff:   6\n",
      "y: 28, yHat: 10, diff:  18\n",
      "y:  4, yHat: 14, diff:  10\n",
      "y:  6, yHat: 13, diff:   7\n",
      "y: 13, yHat: 13, diff:   0\n",
      "y:  2, yHat: 11, diff:   9\n",
      "y:  4, yHat:  8, diff:   4\n",
      "y: 26, yHat: 17, diff:   9\n"
     ]
    }
   ],
   "source": [
    "oModel.train(False) \n",
    "\n",
    "mX, vY = next(iter(oTestDL))\n",
    "mX     = mX.to(DEVICE)\n",
    "hatY   = oModel(mX)\n",
    "\n",
    "hatY = hatY.squeeze().cpu().detach().numpy()\n",
    "y    = vY.cpu().numpy()\n",
    "for i in range(len(r)):    \n",
    "    print('y:{0:3d}, yHat:{1:3d}, diff:{2:4d}'.format(int(y[i]), int(hatY[i]), abs(int(hatY[i])-int(y[i]))))\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

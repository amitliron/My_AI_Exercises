{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13d1781",
   "metadata": {},
   "source": [
    "https://h1ros.github.io/posts/explain-image-classification-by-shap-deep-explainer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b60f98a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchviz import make_dot\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d4a3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a624fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 2\n",
    "learning_rate = 0.01\n",
    "momentum=0.5\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f76e4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beaf6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Convolution Layers\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(10, 20, kernel_size=5),\n",
    "            nn.Dropout(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(320, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(50, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb67fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9a98288",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Convolution Layers\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(10, 20, kernel_size=5),\n",
    "            nn.Dropout(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(320, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(50, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8f389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de52ec6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): ReLU()\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Linear(in_features=320, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=10, bias=True)\n",
       "    (4): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f44499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55940c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output.log(), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            # sum up batch loss\n",
    "            test_loss += F.nll_loss(output.log(),\n",
    "                                    target).item()  \n",
    "            \n",
    "            # get the index of the max log-probability\n",
    "            pred = output.max(1, keepdim=True)[1]  \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(\n",
    "        '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f57bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8000b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:02, 4852507.98it/s]                                                                                                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 7375299.12it/s]                                                                                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1649664it [00:00, 4932745.93it/s]                                                                                                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5120it [00:00, 6325430.48it/s]                                                                                                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST(\n",
    "    'mnist_data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST(\n",
    "    'mnist_data',\n",
    "    train=False,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "136c9770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "images, labels = batch\n",
    "plt.imshow(images[:1][0][0].numpy());\n",
    "plt.title(f'Images for {str(labels[:1][0].numpy())}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f7a3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77dd1d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.318097\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.193446\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.488923\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.962173\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.684220\n",
      "\n",
      "Test set: Average loss: 0.0043, Accuracy: 9101/10000 (91%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.650251\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.578911\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.561695\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.503453\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.405843\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 9432/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model and optimizer\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b4bfec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since shuffle=True, this is a random sample of test data\n",
    "batch = next(iter(test_loader))\n",
    "images, _ = batch\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd2aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d41283f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<shap.explainers._deep.Deep at 0x7f29a42a7af0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background = images[:100]\n",
    "e = shap.DeepExplainer(model, background)\n",
    "e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031df98b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "990d0d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n"
     ]
    }
   ],
   "source": [
    "n_test_images = 10\n",
    "test_images = images[100:100+n_test_images]\n",
    "shap_values = e.shap_values(test_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac1bbb66",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:LightGreen;\">\n",
    "    <center>\n",
    "         Kaggle\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27e9a46",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/competitions/spooky-author-identification/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86de6740",
   "metadata": {},
   "source": [
    "Topic modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853cd6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba6257b7",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:LightGreen;\">\n",
    "    <center>\n",
    "         NLP Notes:\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156bac2b",
   "metadata": {},
   "source": [
    "<li> Stemming identifies the common root form of a word by removing or replacing word suffixes (e.g. “flooding” is stemmed as “flood”) \n",
    "<li> Lemmatization identifies the inflected forms of a word and returns its base form (e.g. “better” is lemmatized as “good”)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6c1ca",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f5777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "361ecfa4",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:LightGreen;\">\n",
    "    <center>\n",
    "         Imports\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fcc8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Auto reload:\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f64426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa8bff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib                          import pyplot\n",
    "from matplotlib.image                    import imread\n",
    "from torchvision.datasets                import ImageFolder\n",
    "from torch.optim.lr_scheduler            import OneCycleLR\n",
    "from sklearn.metrics                     import r2_score\n",
    "from sklearn.feature_extraction.text     import TfidfVectorizer\n",
    "from nltk.stem.porter                    import PorterStemmer\n",
    "from nltk.corpus                         import stopwords\n",
    "from nltk.tokenize                       import sent_tokenize, word_tokenize\n",
    "from nltk.stem                           import WordNetLemmatizer\n",
    "from transformers                        import BertTokenizer\n",
    "from transformers                        import BertModel\n",
    "\n",
    "import numpy                  as np\n",
    "import matplotlib.pyplot      as plt\n",
    "import matplotlib.image       as mpimg\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn               as nn\n",
    "import torch.nn.functional    as F\n",
    "import torch.optim            as optim\n",
    "import pandas                 as pd\n",
    "\n",
    "\n",
    "import torchinfo\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import matplotlib\n",
    "import torchvision\n",
    "import torchinfo\n",
    "import gc \n",
    "import os\n",
    "import time\n",
    "import nltk\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf620642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc1e80c3",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:LightGreen;\">\n",
    "    <center>\n",
    "         Load Data\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38df08ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text author\n",
       "0  This process, however, afforded me no means of...    EAP\n",
       "1  It never once occurred to me that the fumbling...    HPL\n",
       "2  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_FOLDER = \"/home/amitli/Datasets/spooky-author-identification/spooky-author-identification/train.csv\"\n",
    "TEST_FOLDER  = \"/home/amitli/Datasets/spooky-author-identification/spooky-author-identification/test.csv\"\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_FOLDER)\n",
    "df_train.drop(['id'], axis=1, inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d040a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0822eb9",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:LightGreen;\">\n",
    "    <center>\n",
    "         EDA\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa5636ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EAP</th>\n",
       "      <td>7900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HPL</th>\n",
       "      <td>5635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MWS</th>\n",
       "      <td>6044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text\n",
       "author      \n",
       "EAP     7900\n",
       "HPL     5635\n",
       "MWS     6044"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(by='author').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feadd72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a2cfe280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/amitli/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/amitli/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/amitli/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f8d000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ebcc569",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:LightYellow;\">\n",
    "    <center>\n",
    "         TOP tfidf (10 words) of each author\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "be50950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def Stemmer(sentences):\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "        words = word_tokenize(sentences[i])    \n",
    "        words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "        sentences[i]=' '.join(words)\n",
    "    return sentences\n",
    "\n",
    "def Lemmmatizer(sentences):\n",
    "    lemmmatizer = WordNetLemmatizer()\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        words = word_tokenize(sentences[i])  \n",
    "        words = [lemmmatizer.lemmatize(word.lower()) for word in words if word not in set(stopwords.words('english'))]\n",
    "        sentences[i]=' '.join(words)   \n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2938029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cad1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "26344e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: EAP, Top words: ['day' 'eye' 'great' 'howev' 'littl' 'man' 'said' 'say' 'thu' 'time']\n",
      "Author: HPL, Top words: ['came' 'hous' 'like' 'look' 'man' 'night' 'old' 'saw' 'thing' 'time']\n",
      "Author: MWS, Top words: ['day' 'everi' 'eye' 'feel' 'heart' 'life' 'love' 'man' 'raymond' 'time']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=10)\n",
    "authors    = df_train.groupby(by='author')\n",
    "\n",
    "for author in authors:\n",
    "    df_tmp = author[1].reset_index()\n",
    "    res = Lemmmatizer(df_tmp['text'].values)\n",
    "    res = Stemmer(res)\n",
    "    X   = vectorizer.fit_transform(res)\n",
    "    print(f\"Author: {author[0]}, Top words: {vectorizer.get_feature_names_out()}\")\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1234dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e441f537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcee502d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94ac0468",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:LightYellow;\">\n",
    "    <center>\n",
    "         BERT\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcfa9eb",
   "metadata": {},
   "source": [
    "<img src=\"../bert.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccb0efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de94382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c07c794",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:LightYellow;\">\n",
    "    <center>\n",
    "         Create dataset\n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38fce1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1fc305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = {'EAP':0,\n",
    "          'HPL':1,\n",
    "          'MWS':2        \n",
    "          }\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        # 512 - maximum size of tokens that can be fed into BERT model.\n",
    "        \n",
    "        # bert_input = tokenizer()\n",
    "        #       bert_input['input_ids']         - representation of each token\n",
    "        #       bert_input['token_type_ids']    - dentifies in which sequence a token belongs [0/1]\n",
    "        #       bert_input['attention_mask']    - binary mask that identifies whether a token is a real word \n",
    "        #                                         or just padding. \n",
    "        #                                         If the token contains [CLS], [SEP], or any real word\n",
    "        \n",
    "        self.labels = [labels[label] for label in df['author']]\n",
    "        self.texts  = [tokenizer(text, \n",
    "                                padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y     = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179fe548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "327c049a",
   "metadata": {},
   "source": [
    "<H1 style=\"background-color:LightYellow;\">\n",
    "    <center>\n",
    "         Create Model \n",
    "     </center>\n",
    " </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa0dcae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert    = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear  = nn.Linear(768, 3)\n",
    "        self.relu    = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        \n",
    "        #\n",
    "        # pooled_output - embedding vector of [CLS] token\n",
    "        #\n",
    "        vEmbeddingToken, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output                 = self.dropout(pooled_output)\n",
    "        linear_output                  = self.linear(dropout_output)\n",
    "        final_layer                    = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
